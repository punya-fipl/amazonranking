name: Amazon BSR Scraper - Every 2 Hours

on:
  schedule:
    # Runs at 9 AM, 11 AM, 1 PM, 3 PM, 5 PM UTC
    # Adjust timezone: subtract your UTC offset from these times
    # Example: If you're UTC+5:30, subtract 5.5 hours from your desired times
    - cron: '0 9,11,13,15,17 * * *'  # 9 AM to 5 PM every 2 hours (UTC)
  
  workflow_dispatch:  # Allows manual trigger from GitHub UI

jobs:
  scrape-amazon:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4
      
      - name: Run scraper
        run: |
          python amazon_scraper.py
        env:
          TZ: 'Asia/Kolkata'  # Set your timezone
      
      - name: Generate timestamp
        id: timestamp
        run: echo "timestamp=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT
      
      - name: Commit and push results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add amazon_bsr_results.csv amazon_bsr_results.json || true
          git commit -m "Update BSR data - ${{ steps.timestamp.outputs.timestamp }}" || echo "No changes to commit"
          git push || echo "No changes to push"
      
      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: bsr-results-${{ steps.timestamp.outputs.timestamp }}
          path: |
            amazon_bsr_results.csv
            amazon_bsr_results.json
          retention-days: 30
      
      - name: Create summary
        run: |
          echo "## Scraping Results" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** ${{ steps.timestamp.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f amazon_bsr_results.csv ]; then
            echo "✅ CSV file generated successfully" >> $GITHUB_STEP_SUMMARY
            echo "**File size:** $(du -h amazon_bsr_results.csv | cut -f1)" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ CSV file not generated" >> $GITHUB_STEP_SUMMARY
          fi
